[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción",
    "section": "",
    "text": "Bienvenidos\nLa idea de esta página es ser una ayuda con materiales y resolución de los ejercicos del practico del curso de Introducción a los Procesos Estocásticos.\n\n\nCalendario\n\n\n\n\n\n\n\n\n\nSemana\nFecha\nTema\nNota\n\n\n\n\n1\n19-Aug-25 Tue\n• Presentación• Introducción procesos estocásticos• Problema de la ruina\n\n\n\n\n21-Aug-25 Thu\n• Recurrencia para proba de ruina• Ecuaciones en diferencias• Fórmula para proba de ruina• Límite cuando \\(S=\\infty\\)\nP1\n\n\n2\n26-Aug-25 Tue\n• Duración media del juego• Recurrencia para duración media• Fórmula para duración media• Límite cuando \\(S=\\infty\\)\nP1\n\n\n\n28-Aug-25 Thu",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "practicos_solucion/practico1-solucion.html",
    "href": "practicos_solucion/practico1-solucion.html",
    "title": "Soluciones Practico 1",
    "section": "",
    "text": "Code\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n\n\n\n\nEscribir un programa mediante el cual simular y visualizar la evolución del capital del jugador A\n\ndef apuesta(p:float):\n  if np.random.random() &lt; p:\n    return 1\n  else:\n    return -1\n\n\ndef juego(p:float, S:int, X0:int):\n  trayectoria = [X0]\n  X = X0\n  while (X &gt; 0) and (X &lt; S):\n    X += apuesta(p)\n    trayectoria.append(X)\n  return trayectoria\n\n\np = 0.5\nS = 10\nX0 = 5\ntrayectoria = juego(p, S, X0)\n\n\n\nCode\nprint('Trayectoria: ', trayectoria)\n\n\nTrayectoria:  [5, 4, 3, 4, 3, 2, 1, 2, 1, 2, 3, 4, 3, 2, 3, 2, 1, 0]\n\n\n\n\nCode\nplt.figure(figsize=(8,5))\nplt.plot(trayectoria, marker='o')\nplt.title('Juego de la ruina - Una trayectoria')\nplt.ylim(-0.5, S+0.5)\nplt.axhline(y=S, linestyle='--')\nplt.axhline(y=0, linestyle='--')\nplt.xlabel(r'Turno $n$')\nplt.ylabel(r'Capital $X_n$')\nplt.show()\n\n\n\n\n\n\n\n\n\n\ntodas_trayectorias = []\nfor _ in range(5):\n  todas_trayectorias.append(juego(p, S, X0))\n\n\n\nCode\nplt.figure(figsize=(8,5))\nfor trayectoria in todas_trayectorias:\n  plt.plot(trayectoria, marker='o')\nplt.title('Juego de la ruina - Varias trayectorias') # Added title for clarity\nplt.ylim(-0.5, S+0.5)\nplt.axhline(y=S, linestyle='--')\nplt.axhline(y=0, linestyle='--')\nplt.xlabel(r'Turno $n$')\nplt.ylabel(r'Capital $X_n$')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nDesarrollar el programa anterior de manera de estimar, mediante la simulación de un número adecuado de trayectorias del capital del jugador A, la probabilidad de ruina.\n\ndef probabilidad_ruina(p:float, S:int, X0:int, N:int):\n  ruinas = 0\n  for _ in range(N):\n    trayectoria = juego(p, S, X0)\n    if trayectoria[-1] == 0:\n      ruinas += 1\n  return ruinas/N\n\n\np = 0.7\nS = 10\nX0 = 5\nN = 10000\nprint(f'Probabilidad de ruina: {probabilidad_ruina(p, S, X0, N)}')\n\nProbabilidad de ruina: 0.0141\n\n\n\nfS = []\nfor X0 in range(S+1):\n  fS.append(probabilidad_ruina(p, S, X0, N))\n\n\n\nCode\nplt.figure(figsize=(8,5))\nplt.plot(fS, marker='o')\nplt.title('Probabilidad de ruina')\nplt.xlabel(r'Capital inicial $X_0$')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef probabilidad_ruina_Markov(p:float, S:int, X0:int, X1:int, N:int):\n  ruinas = 0\n  condicion = 0\n  for _ in range(N):\n    trayectoria = juego(p, S, X0)\n    if trayectoria[1] == X1:\n      condicion += 1\n      if trayectoria[-1] == 0:\n        ruinas += 1\n  return ruinas/condicion\n\n\np = 0.5\nS = 10\nX0 = 5\nN = 10000\np0 = probabilidad_ruina(p, S, X0+1, N)\np1 = probabilidad_ruina_Markov(p, S, X0, X0+1, N)\nprint(f'p0: {p0}\\np1: {p1}')\n\np0: 0.3962\np1: 0.39119222376512597",
    "crumbs": [
      "Soluciones",
      "Soluciones Practico 1"
    ]
  },
  {
    "objectID": "practicos_solucion/practico1-solucion.html#ejercicio-1",
    "href": "practicos_solucion/practico1-solucion.html#ejercicio-1",
    "title": "Soluciones Practico 1",
    "section": "",
    "text": "Code\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n\n\n\n\nEscribir un programa mediante el cual simular y visualizar la evolución del capital del jugador A\n\ndef apuesta(p:float):\n  if np.random.random() &lt; p:\n    return 1\n  else:\n    return -1\n\n\ndef juego(p:float, S:int, X0:int):\n  trayectoria = [X0]\n  X = X0\n  while (X &gt; 0) and (X &lt; S):\n    X += apuesta(p)\n    trayectoria.append(X)\n  return trayectoria\n\n\np = 0.5\nS = 10\nX0 = 5\ntrayectoria = juego(p, S, X0)\n\n\n\nCode\nprint('Trayectoria: ', trayectoria)\n\n\nTrayectoria:  [5, 4, 3, 4, 3, 2, 1, 2, 1, 2, 3, 4, 3, 2, 3, 2, 1, 0]\n\n\n\n\nCode\nplt.figure(figsize=(8,5))\nplt.plot(trayectoria, marker='o')\nplt.title('Juego de la ruina - Una trayectoria')\nplt.ylim(-0.5, S+0.5)\nplt.axhline(y=S, linestyle='--')\nplt.axhline(y=0, linestyle='--')\nplt.xlabel(r'Turno $n$')\nplt.ylabel(r'Capital $X_n$')\nplt.show()\n\n\n\n\n\n\n\n\n\n\ntodas_trayectorias = []\nfor _ in range(5):\n  todas_trayectorias.append(juego(p, S, X0))\n\n\n\nCode\nplt.figure(figsize=(8,5))\nfor trayectoria in todas_trayectorias:\n  plt.plot(trayectoria, marker='o')\nplt.title('Juego de la ruina - Varias trayectorias') # Added title for clarity\nplt.ylim(-0.5, S+0.5)\nplt.axhline(y=S, linestyle='--')\nplt.axhline(y=0, linestyle='--')\nplt.xlabel(r'Turno $n$')\nplt.ylabel(r'Capital $X_n$')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nDesarrollar el programa anterior de manera de estimar, mediante la simulación de un número adecuado de trayectorias del capital del jugador A, la probabilidad de ruina.\n\ndef probabilidad_ruina(p:float, S:int, X0:int, N:int):\n  ruinas = 0\n  for _ in range(N):\n    trayectoria = juego(p, S, X0)\n    if trayectoria[-1] == 0:\n      ruinas += 1\n  return ruinas/N\n\n\np = 0.7\nS = 10\nX0 = 5\nN = 10000\nprint(f'Probabilidad de ruina: {probabilidad_ruina(p, S, X0, N)}')\n\nProbabilidad de ruina: 0.0141\n\n\n\nfS = []\nfor X0 in range(S+1):\n  fS.append(probabilidad_ruina(p, S, X0, N))\n\n\n\nCode\nplt.figure(figsize=(8,5))\nplt.plot(fS, marker='o')\nplt.title('Probabilidad de ruina')\nplt.xlabel(r'Capital inicial $X_0$')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef probabilidad_ruina_Markov(p:float, S:int, X0:int, X1:int, N:int):\n  ruinas = 0\n  condicion = 0\n  for _ in range(N):\n    trayectoria = juego(p, S, X0)\n    if trayectoria[1] == X1:\n      condicion += 1\n      if trayectoria[-1] == 0:\n        ruinas += 1\n  return ruinas/condicion\n\n\np = 0.5\nS = 10\nX0 = 5\nN = 10000\np0 = probabilidad_ruina(p, S, X0+1, N)\np1 = probabilidad_ruina_Markov(p, S, X0, X0+1, N)\nprint(f'p0: {p0}\\np1: {p1}')\n\np0: 0.3962\np1: 0.39119222376512597",
    "crumbs": [
      "Soluciones",
      "Soluciones Practico 1"
    ]
  },
  {
    "objectID": "practicos_solucion/practico1-solucion.html#ejercicio-2",
    "href": "practicos_solucion/practico1-solucion.html#ejercicio-2",
    "title": "Soluciones Practico 1",
    "section": "Ejercicio 2",
    "text": "Ejercicio 2\n\nParte a\n\nEstimación de la duración esperada del juego\n\ndef simular_duracion_juego(p: float, S: int, X0: int) -&gt; int:\n    trayectoria = [X0]\n    X = X0\n    turnos = 0\n    while (X &gt; 0) and (X &lt; S):\n        X += apuesta(p) ## funcion del ejercicio 1\n        turnos += 1\n    return turnos\n\n\ndef estimar_duracion_esperada(p: float, S: int, X0: int, N: int) -&gt; float:\n    duraciones = []\n    for _ in range(N):\n        duraciones.append(simular_duracion_juego(p, S, X0))\n    return np.mean(duraciones)\n\n\n\n(i) Duración esperada vs. capital inicial \\(X_0 = k\\)\n\np_ej2_i = 0.5\nS_ej2_i = 10\nN_ej2_i = 5000 \n\nduracion_vs_X0 = []\nfor k_val in range(S_ej2_i + 1):\n    duracion_vs_X0.append(estimar_duracion_esperada(p_ej2_i, S_ej2_i, k_val, N_ej2_i))\n\nprint(\"Duración esperada vs. Capital inicial:\", [float(d) for d in duracion_vs_X0])\n\nDuración esperada vs. Capital inicial: [0.0, 8.5572, 16.3292, 20.8324, 23.7448, 25.1652, 24.4272, 20.8436, 15.5248, 9.3192, 0.0]\n\n\n\n\nCode\nplt.figure(figsize=(8,5))\nplt.plot(range(S_ej2_i + 1), duracion_vs_X0, marker='o')\nplt.title(f'Duración Esperada vs. Capital Inicial (S={S_ej2_i}, p={p_ej2_i})')\nplt.xlabel(r'Capital inicial $X_0$')\nplt.ylabel('Duración Esperada del Juego')\nplt.xticks(range(S_ej2_i + 1))\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(ii) Duración esperada vs. probabilidad \\(p\\)\n\nX0_ej2_ii = 5\nS_ej2_ii = 10\nN_ej2_ii = 5000 \n\nprobabilidades = np.linspace(0.1, 0.9, 9) \nduracion_vs_p = []\nfor p_val in probabilidades:\n    duracion_vs_p.append(estimar_duracion_esperada(p_val, S_ej2_ii, X0_ej2_ii, N_ej2_ii))\n\nprint(\"Duración esperada vs. Probabilidad p:\", [float(d) for d in duracion_vs_p])\n\nDuración esperada vs. Probabilidad p: [6.2168, 8.254, 12.3132, 19.2708, 25.3448, 19.6704, 12.3836, 8.302, 6.2856]\n\n\n\n\nCode\nplt.figure(figsize=(8,5))\nplt.plot(probabilidades, duracion_vs_p, marker='o')\nplt.title(f'Duración Esperada vs. Probabilidad p (S={S_ej2_ii}, X0={X0_ej2_ii})')\nplt.xlabel(r'Probabilidad $p$ de ganar')\nplt.ylabel('Duración Esperada del Juego')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nParte b\nVisualizar las estimaciones de la duración esperada del juego y compararlas con las correspondientes expresiones analíticas.\n\nFunciones analíticas\n\ndef prob_ruina_analitica(p: float, S: int, k: int) -&gt; float:\n    q = 1 - p\n    if p == 0.5:\n        return (S - k) / S\n    else:\n        ratio = q / p\n        return (ratio**k - ratio**S) / (1 - ratio**S)\n\n\n\nCode\ndef duracion_esperada_analitica(p: float, S: int, k: int) -&gt; float:\n    q = 1 - p\n    if p == 0.5:\n        return k * (S - k)\n    else:\n        prob_ganar_analitica = 1 - prob_ruina_analitica(p, S, k)\n        if p != q:\n            return (k / (q - p)) - (S / (q - p)) * ((1 - (q / p)**k) / (1 - (q / p)**S))\n        else:\n            return k * (S - k)\n\n\n\n\n(i) Duración esperada vs. capital inicial \\(X_0 = k\\) (Comparación)\n\nduracion_analitica_X0 = []\nfor k_val in range(S_ej2_i + 1):\n    duracion_analitica_X0.append(duracion_esperada_analitica(p_ej2_i, S_ej2_i, k_val))\n\nprint(\"Duración analítica vs. Capital inicial:\", [float(d) for d in duracion_analitica_X0])\n\nDuración analítica vs. Capital inicial: [0.0, 9.0, 16.0, 21.0, 24.0, 25.0, 24.0, 21.0, 16.0, 9.0, 0.0]\n\n\n\n\nCode\nplt.figure(figsize=(10,6)) \nplt.plot(range(S_ej2_i + 1), duracion_vs_X0, marker='o', label='Simulado', linestyle='--')\nplt.plot(range(S_ej2_i + 1), duracion_analitica_X0, marker='x', label='Analítico', linestyle='-')\nplt.title(f'Comparación Duración Esperada vs. Capital Inicial (S={S_ej2_i}, p={p_ej2_i})')\nplt.xlabel(r'Capital inicial $X_0$')\nplt.ylabel('Duración Esperada del Juego')\nplt.xticks(range(S_ej2_i + 1))\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(ii) Duración esperada vs. probabilidad \\(p\\) (Comparación)\n\nduracion_analitica_p = []\nfor p_val in probabilidades:\n    duracion_analitica_p.append(duracion_esperada_analitica(p_val, S_ej2_ii, X0_ej2_ii))\n\nprint(\"Duración analítica vs. Probabilidad p:\", [float(d) for d in duracion_analitica_p])\n\nDuración analítica vs. Probabilidad p: [6.249788314987299, 8.317073170731707, 12.14369501466276, 19.181818181818183, 25.0, 19.18181818181818, 12.143695014662754, 8.317073170731707, 6.249788314987299]\n\n\n\n\nCode\nplt.figure(figsize=(10,6))\nplt.plot(probabilidades, duracion_vs_p, marker='o', label='Simulado', linestyle='--')\nplt.plot(probabilidades, duracion_analitica_p, marker='x', label='Analítico', linestyle='-')\nplt.title(f'Comparación Duración Esperada vs. Probabilidad p (S={S_ej2_ii}, X0={X0_ej2_ii})')\nplt.xlabel(r'Probabilidad $p$ de ganar')\nplt.ylabel('Duración Esperada del Juego')\nplt.grid(True)\nplt.legend()\nplt.show()",
    "crumbs": [
      "Soluciones",
      "Soluciones Practico 1"
    ]
  },
  {
    "objectID": "practicos_solucion/practico1-solucion.html#ejercicio-3",
    "href": "practicos_solucion/practico1-solucion.html#ejercicio-3",
    "title": "Soluciones Practico 1",
    "section": "Ejercicio 3",
    "text": "Ejercicio 3\nConsideramos un juego de ruina del jugador con posibilidad de empate (también llamado lazy random walk): en el tiempo \\(n\\) la ganancia \\(X_n\\) del Jugador A puede aumentar en una unidad con probabilidad \\(r \\in (0; 1/2]\\), disminuir en una unidad con probabilidad \\(r\\), o permanecer igual con probabilidad \\(1 - 2r\\). Definimos\n\\[ f (k) := P(RA | X_0 = k) \\]\ncomo la probabilidad de ruina del Jugador A, y\n\\[ h(k) := E[T_{0;S} | X_0 = k] \\]\ncomo la esperanza de la duración del juego \\(T_{0;S}\\) comenzando en \\(X_0 = k\\), para \\(k = 0; 1; \\dots ; S\\).\n\na) Ecuación en Diferencias para la Probabilidad de Ruina \\(u_k\\)\nPara encontrar la ecuación que satisface \\(u_k\\), la probabilidad de que el Jugador A se arruine comenzando con una fortuna k, utilizamos un análisis de primer paso. Consideramos el resultado del primer movimiento desde el estado k:\n\nGana: Con probabilidad \\(p\\), la fortuna se convierte en \\(k+1\\). La probabilidad de ruina desde este nuevo estado es \\(u_{k+1}\\).\nPierde: Con probabilidad \\(q\\), la fortuna se convierte en \\(k-1\\). La probabilidad de ruina desde este nuevo estado es \\(u_{k-1}\\).\nEmpata: Con probabilidad \\(r\\), la fortuna permanece en \\(k\\). La probabilidad de ruina sigue siendo \\(u_k\\).\n\nPor la ley de probabilidad total, podemos escribir: \\(u_k = p \\cdot u_{k+1} + q \\cdot u_{k-1} + r \\cdot u_k\\)\nPara simplificar, agrupamos los términos de \\(u_k\\): \\(u_k (1-r) = p \\cdot u_{k+1} + q \\cdot u_{k-1}\\)\nDado que \\(p+q+r=1\\), tenemos que \\(1-r=p+q\\). Sustituyendo: \\((p+q)u_k = p \\cdot u_{k+1} + q \\cdot u_{k-1}\\)\nReordenando obtenemos la ecuación en diferencias homogénea:\n\\(pu_{k+1} - (p+q)u_k + qu_{k-1} = 0, \\text{para } 1 \\leq k \\leq N-1\\) Las condiciones de contorno son los estados absorbentes:\n\nSi el jugador comienza en \\(k=0\\), ya está en la ruina: \\(u_0=1\\).\nSi el jugador comienza en \\(k=N\\), ha ganado todo, por lo que no puede arruinarse: \\(u_N=0\\).\n\n\\(u_0=1, u_N=0\\)\n\n\nb) Solución de la Ecuación Homogénea\nResolvemos la ecuación mediante su polinomio característico: \\(p\\lambda^2 - (p+q)\\lambda + q = 0\\)\nEste polinomio se puede factorizar como \\((p\\lambda-q)(\\lambda-1)=0\\). Las raíces son: \\(\\lambda_1=1 \\text{ y } \\lambda_2 = \\frac{q}{p}\\).\nTenemos dos casos:\nCaso 1: \\(p \\neq q\\) Las raíces son distintas. La solución general es de la forma: \\(u_k = A(\\lambda_1)^k + B(\\lambda_2)^k = A+B\\left(\\frac{q}{p}\\right)^k\\)\nAplicamos las condiciones de contorno:\n\\(u_0 = 1 \\implies A+B=1\\)\n\\(u_N = 0 \\implies A+B\\left(\\frac{q}{p}\\right)^N = 0\\)\nResolviendo el sistema, obtenemos \\(B = \\frac{1}{1-(q/p)^N}\\) y \\(A = -B(q/p)^N\\). La solución es:\n\\(u_k = \\frac{(q/p)^k - (q/p)^N}{1-(q/p)^N}\\)\nCaso 2: \\(p=q\\) Las raíces son iguales (\\(\\lambda_1=\\lambda_2=1\\)). La solución general es: \\(u_k = A(1)^k + Bk(1)^k = A+Bk\\)\nAplicamos las condiciones de contorno:\n\\(u_0 = 1 \\implies A=1\\)\n\\(u_N = 0 \\implies A+BN=0 \\implies 1+BN=0 \\implies B = -\\frac{1}{N}\\)\nLa solución es:\n\\(u_k = 1-\\frac{k}{N} = \\frac{N-k}{N}\\)\nCompatibilidad con la intuición: Sí, la solución es compatible. Notablemente, la probabilidad de ruina no depende de \\(r\\) (la probabilidad de empate). Un empate simplemente retrasa el juego, pero no altera el sesgo fundamental (\\(p\\) vs \\(q\\)) que determina el resultado final. La probabilidad de ruina es idéntica a la del juego de ruina del jugador estándar sin empates.\n\n\nc) Ecuación en Diferencias para la Duración Media \\(d_k\\)\nNuevamente, usamos un análisis de primer paso para \\(d_k\\), la duración media del juego comenzando en \\(k\\). Cada paso toma 1 unidad de tiempo. \\(d_k = 1 + p \\cdot d_{k+1} + q \\cdot d_{k-1} + r \\cdot d_k\\)\nAgrupando los términos de \\(d_k\\) y usando \\(1-r=p+q\\): \\((1-r)d_k = 1 + p \\cdot d_{k+1} + q \\cdot d_{k-1}\\) \\((p+q)d_k = 1 + p \\cdot d_{k+1} + q \\cdot d_{k-1}\\)\nReordenando, obtenemos la ecuación en diferencias no homogénea:\n\\(pd_{k+1} - (p+q)d_k + qd_{k-1} = -1, \\text{para } 1 \\leq k \\leq N-1\\) Las condiciones de contorno son: Si el juego comienza en un estado absorbente, la duración es 0.\n\\(d_0=0, d_N=0\\)\n\n\nd) Solución Particular de la Ecuación para \\(d_k\\)\nBuscamos una solución particular \\(d_k^{(p)}\\) para la ecuación no homogénea.\nCaso 1: \\(p \\neq q\\) Intentamos con una solución de la forma \\(d_k^{(p)}=Ck\\). \\(pC(k+1)-(p+q)Ck+qC(k-1)=-1\\) \\(pCk+pC-pCk-qCk+qCk-qC=-1\\) \\(C(p-q)=-1 \\implies C = \\frac{1}{q-p}\\)\nUna solución particular es:\n\\(d_k^{(p)} = \\frac{k}{q-p}\\)\nCaso 2: \\(p=q\\) El método anterior falla porque \\(Ck\\) es parte de la solución homogénea. Intentamos con \\(d_k^{(p)} = Ck^2\\). La ecuación es \\(pd_{k+1}-2pd_k+pd_{k-1}=-1\\). \\(pC(k+1)^2 - 2pCk^2 + pC(k-1)^2 = -1\\) \\(pC(k^2+2k+1 - 2k^2 + k^2-2k+1) = -1\\) \\(pC(2)=-1 \\implies C = -\\frac{1}{2p}\\)\nUna solución particular es:\n\\(d_k^{(p)} = -\\frac{k^2}{2p}\\)\n\n\ne) Solución Completa para \\(d_k\\)\nLa solución general es la suma de la solución de la homogénea (\\(d_k^{(h)}\\)) y una particular (\\(d_k^{(p)}\\)).\nCaso 1: \\(p \\neq q\\) \\(d_k = d_k^{(h)} + d_k^{(p)} = A+B\\left(\\frac{q}{p}\\right)^k + \\frac{k}{q-p}\\)\nAplicamos las condiciones de contorno (\\(d_0=0, d_N=0\\)):\n\\(d_0=0 \\implies A+B=0 \\implies A=-B\\)\n\\(d_N=0 \\implies A+B\\left(\\frac{q}{p}\\right)^N + \\frac{N}{q-p} = 0\\)\nSustituyendo \\(A=-B\\): \\(B\\left(\\left(\\frac{q}{p}\\right)^N - 1\\right) = -\\frac{N}{q-p} \\implies B = \\frac{N}{(p-q)((q/p)^N-1)}\\)\nLa solución completa es:\n\\(d_k = \\frac{k}{q-p} + \\frac{N}{(p-q)(1-(q/p)^N)}\\left(\\left(\\frac{q}{p}\\right)^k - 1\\right)\\)\nCaso 2: \\(p=q\\) \\(d_k = d_k^{(h)} + d_k^{(p)} = A+Bk-\\frac{k^2}{2p}\\)\nAplicamos las condiciones de contorno (\\(d_0=0, d_N=0\\)):\n\\(d_0=0 \\implies A=0\\)\n\\(d_N=0 \\implies BN - \\frac{N^2}{2p} = 0 \\implies B = \\frac{N}{2p}\\)\nLa solución completa es:\n\\(d_k = \\frac{Nk}{2p} - \\frac{k^2}{2p} = \\frac{k(N-k)}{2p}\\)\n\n\nf) Comportamiento de la Duración Media \\(d_k\\) cuando \\(p=q\\)\nPara el caso simétrico (\\(p=q\\)), la duración media es:\n\\(d_k = \\frac{k(N-k)}{2p}\\)\nRecordando que \\(p+q+r=1\\) y \\(p=q\\), tenemos \\(2p+r=1 \\implies 2p=1-r\\). La fórmula se puede reescribir como:\n\\(d_k = \\frac{k(N-k)}{1-r}\\)\nCompatibilidad con la intuición: Sí, esta solución es muy intuitiva por dos razones principales:\n\nForma de la función: La función \\(k(N-k)\\) es una parábola invertida que es 0 en \\(k=0\\) y \\(k=N\\). Alcanza su máximo en \\(k=N/2\\). Esto significa que la duración esperada del juego es mayor cuando el jugador comienza a mitad de camino, lo más lejos posible de ambos estados absorbentes (ruina o victoria total).\nDependencia de \\(r\\): La duración media \\(d_k\\) es inversamente proporcional a \\(1-r\\). A medida que la probabilidad de empate \\(r\\) se acerca a 1, el denominador \\(1-r\\) se acerca a 0, y la duración media \\(d_k \\to \\infty\\). Esto tiene perfecto sentido: si los jugadores casi siempre empatan, el juego se “congela” en su estado actual y tardará una cantidad de tiempo extremadamente larga en llegar a su fin.",
    "crumbs": [
      "Soluciones",
      "Soluciones Practico 1"
    ]
  },
  {
    "objectID": "practicos_letra/practicos.html",
    "href": "practicos_letra/practicos.html",
    "title": "Practicos",
    "section": "",
    "text": "Practicos\nContenido de la sección de Practicos."
  },
  {
    "objectID": "practicos_letra/practico1-letra.html",
    "href": "practicos_letra/practico1-letra.html",
    "title": "Practico 1",
    "section": "",
    "text": "Considere el problema de la ruina del jugador.\n\nEscribir un programa mediante el cual simular y visualizar la evolución del capital del jugador A.\nDesarrollar el programa anterior de manera de estimar, mediante la simulación de un número adecuado de trayectorias del capital de jugador A:\nla probabilidad de ruina del jugador A, en función de su estado inicial \\(X_0 = k\\), para valores asignados del capital total \\(S\\) y de la probabilidad, \\(p\\), de que el jugador A gane en cada etapa del juego;\n\n\nla probabilidad de ruina del jugador A, en función de su probabilidad \\(p\\) de ganar en cada etapa del juego, para valores asignados del capital total \\(S\\) y del estado inicial \\(X_0 = k\\).\nVisualizar las estimaciones de la probabilidad de ruina del jugador A y compararlas con las correspondientes expresiones analíticas.",
    "crumbs": [
      "Practicos",
      "Practico 1"
    ]
  },
  {
    "objectID": "practicos_letra/practico1-letra.html#ejercicio-1",
    "href": "practicos_letra/practico1-letra.html#ejercicio-1",
    "title": "Practico 1",
    "section": "",
    "text": "Considere el problema de la ruina del jugador.\n\nEscribir un programa mediante el cual simular y visualizar la evolución del capital del jugador A.\nDesarrollar el programa anterior de manera de estimar, mediante la simulación de un número adecuado de trayectorias del capital de jugador A:\nla probabilidad de ruina del jugador A, en función de su estado inicial \\(X_0 = k\\), para valores asignados del capital total \\(S\\) y de la probabilidad, \\(p\\), de que el jugador A gane en cada etapa del juego;\n\n\nla probabilidad de ruina del jugador A, en función de su probabilidad \\(p\\) de ganar en cada etapa del juego, para valores asignados del capital total \\(S\\) y del estado inicial \\(X_0 = k\\).\nVisualizar las estimaciones de la probabilidad de ruina del jugador A y compararlas con las correspondientes expresiones analíticas.",
    "crumbs": [
      "Practicos",
      "Practico 1"
    ]
  },
  {
    "objectID": "practicos_letra/practico1-letra.html#ejercicio-2",
    "href": "practicos_letra/practico1-letra.html#ejercicio-2",
    "title": "Practico 1",
    "section": "Ejercicio 2",
    "text": "Ejercicio 2\nConsidere el problema de la ruina del jugador y, en particular, la variable aleatoria \\(T_{0;S}\\) = duración del juego.\n\nAmpliar el programa de computación desarrollado en el ejercicio anterior a los efectos de estimar, mediante la simulación de un número adecuado de trayectorias del capital de jugador A:\nla duración esperada del juego, en función del capital inicial del jugador A, \\(X_0 = k\\), para valores asignados del capital total \\(S\\) y de la probabilidad, \\(p\\), de que el jugador A gane en cada etapa del juego;\n\n\nla duración esperada del juego, en función de la probabilidad, \\(p\\), de que el jugador A gane en cada etapa del juego, para valores asignados del capital total \\(S\\) y del estado inicial \\(X_0 = k\\).\n\n\nVisualizar las estimaciones de la duración esperada del juego y compararlas con las correspondientes expresiones analíticas.",
    "crumbs": [
      "Practicos",
      "Practico 1"
    ]
  },
  {
    "objectID": "practicos_letra/practico1-letra.html#ejercicio-3",
    "href": "practicos_letra/practico1-letra.html#ejercicio-3",
    "title": "Practico 1",
    "section": "Ejercicio 3",
    "text": "Ejercicio 3\nConsideramos un juego de ruina del jugador con posibilidad de empate (también llamado lazy random walk): en el tiempo \\(n\\) la ganancia \\(X_n\\) del Jugador A puede aumentar en una unidad con probabilidad \\(r \\in (0; 1/2]\\), disminuir en una unidad con probabilidad \\(r\\), o permanecer igual con probabilidad \\(1 - 2r\\). Definimos\n\\[ f (k) := P(RA | X_0 = k) \\]\ncomo la probabilidad de ruina del Jugador A, y\n\\[ h(k) := E[T_{0;S} | X_0 = k] \\]\ncomo la esperanza de la duración del juego \\(T_{0;S}\\) comenzando en \\(X_0 = k\\), para \\(k = 0; 1; \\dots ; S\\).\n\nUsando first step analysis, escriba la ecuación en diferencias que satisface \\(f (k)\\) y sus condiciones de contorno, \\(k = 0; 1; \\dots ; S\\). Nos referiremos a esta ecuación como la ecuación homogénea.\nResuelva la ecuación homogénea del apartado (a) por el método de su preferencia. ¿Es esta solución compatible con su intuición del problema? ¿Por qué?\nUsando first step analysis, escriba la ecuación en diferencias que satisface \\(h(k)\\) y sus condiciones de contorno, \\(k = 0; 1; \\dots ; S\\).\nEncuentre una solución particular de la ecuación del apartado (c).\nResuelva por completo la ecuación del apartado (c). Sugerencia: recuerde que la solución general es la suma de una solución particular y una solución de la ecuación homogénea.\n¿Cómo se comporta la duración media \\(h(k)\\) cuando \\(r \\to 0\\)? ¿Es esta solución compatible con su intuición del problema? ¿Por qué?",
    "crumbs": [
      "Practicos",
      "Practico 1"
    ]
  },
  {
    "objectID": "practicos_letra/practico1-letra.html#ejercicio-4",
    "href": "practicos_letra/practico1-letra.html#ejercicio-4",
    "title": "Practico 1",
    "section": "Ejercicio 4",
    "text": "Ejercicio 4\nConsideramos un proceso en tiempo discreto \\((X_n)_{n\\ge 0}\\) que modela la fortuna de un jugador con estados en \\(\\{0; 1; \\dots ; S\\}\\), con probabilidades de transición\n\\[ P(X_{n+1} = k + 1 | X_n = k) = p; \\quad k = 0; 1; \\dots ; S - 1; \\] \\[ P(X_{n+1} = k - 1 | X_n = k) = q; \\quad k = 1; 2; \\dots ; S; \\]\ny además\n\\[ P(X_{n+1} = 0 | X_n = 0) = q; \\]\npara todo \\(n \\in \\mathbb{N} = \\{0; 1; 2; \\dots\\}\\), donde \\(q = 1 - p\\) y \\(p \\in (0; 1]\\). En este modelo, al alcanzar el estado 0 el jugador puede “rebotar” (quedarse en 0 con probabilidad \\(q\\) o pasar a 1 con probabilidad \\(p\\)). Sea\n\\[ W = \\bigcup_{n \\in \\mathbb{N}} \\{X_n = S\\} \\]\nel evento de que el jugador finalmente gana la partida.\n\nDefina\n\n\\[ g(k) := P(W | X_0 = k); \\]\nla probabilidad de ganar habiendo partido del estado \\(k \\in \\{0; 1; \\dots ; S\\}\\). Usando first step analysis, escriba las ecuaciones en diferencias satisfechas por \\(g(k)\\), \\(k = 0; 1; \\dots ; S - 1\\), junto con sus condiciones de contorno (que pueden no darse de forma explícita). Esta pregunta es estándar, pero hay que prestar atención al comportamiento especial en el estado 0.\n\nObtenga \\(P(W | X_0 = k)\\) para todo \\(k = 0; 1; \\dots ; S\\) como la solución única del sistema de ecuaciones planteado en el punto 1.\n\nObservación: La respuesta es muy simple e intuitiva, pero se requiere una prueba (matemática).\n\nSea\n\n\\[ T_S := \\inf\\{n \\ge 0 : X_n = S\\} \\]\nel primer tiempo de llegada a \\(S\\) del proceso \\((X_n)_{n\\ge 0}\\), y\n\\[ h(k) := E[T_S | X_0 = k] \\]\nel tiempo esperado hasta que el jugador gana, partiendo de \\(k \\in \\{0; 1; \\dots ; S\\}\\). Usando first step analysis, escriba las ecuaciones en diferencias satisfechas por \\(h(k)\\) para \\(k = 0; 1; \\dots ; S - 1\\) e indique las condiciones de contorno correspondientes.\nNota: el estado 0 requiere especial cuidado; la ecuación para \\(h(0)\\) adquiere una forma particular y puede verse como una segunda condición de contorno.\n\nCalcule \\(E[T_S | X_0 = k]\\) para todo \\(k = 0; 1; \\dots ; S\\) resolviendo las ecuaciones del punto 3.\n\nSugerencia: Esta cuestión es más difícil que el punto 2 y puede omitirse en una primera lectura (su resultado no se usa luego). Se puede resolver la ecuación homogénea para \\(k = 1; 2; \\dots ; S - 1\\); una solución particular se obtiene observando que aquí cuenta el tiempo hasta que gana el Jugador A (no B). Como de costumbre, hay que tratar por separado los casos \\(p \\neq q\\) y \\(p = q = 1/2\\). La fórmula para \\(p = 1\\) es intuitiva y puede ayudar a verificar el resultado.\n\nDefina ahora\n\n\\[ T_0 := \\inf\\{n \\ge 0 : X_n = 0\\} \\]\ncomo el primer tiempo de llegada a 0. Escriba el valor de\n\\[ p_k := P(T_S &lt; T_0 | X_0 = k); \\]\ncomo función de \\(p\\), \\(S\\) y \\(k\\), para \\(k = 0; 1; \\dots ; S\\).\nNota: el evento \\(\\{T_S &lt; T_0\\}\\) significa “gana el Jugador A”.\n\nExplique por qué vale la igualdad (aplique propiedad de Markov y homogeneidad temporal)\n\n\\[ P(T_S &lt; T_0 | X_1 = k + 1; X_0 = k) = P(T_S &lt; T_0 | X_0 = k + 1); \\]\npara \\(k = 0; 1; \\dots ; S - 1\\) (basta una explicación en palabras).\n\nUsando la relación anterior, muestre que la probabilidad\n\n\\[ P(X_1 = k + 1 | X_0 = k \\text{ y } T_S &lt; T_0) = \\frac{p p_{k+1}}{p_k}; \\]\nde un paso hacia arriba sabiendo que primero se alcanza \\(S\\) es\npara \\(k = 1; 2; \\dots ; S - 1\\), donde \\(p_k\\) es el resultado del punto 5. ¿Cómo se compara esta probabilidad con el valor incondicional \\(p\\)?\n\nCalcule la probabilidad\n\n\\[ P(X_1 = k - 1 | X_0 = k \\text{ y } T_0 &lt; T_S); \\quad k = 1; 2; \\dots ; S; \\]\nde un paso hacia abajo sabiendo que primero se alcanza 0, usando un argumento análogo al del punto 7.\n\nSea\n\n\\[ \\hat{h}(k) := E[T_S | X_0 = k; T_S &lt; T_0]; \\quad k = 1; 2; \\dots ; S; \\]\nel tiempo esperado hasta que el jugador gana, condicionado a que nunca se alcance el estado 0. Usando las probabilidades de transición condicionadas de los puntos 7 y 8, plantee las ecuaciones en diferencias satisfechas por \\(\\hat{h}(k)\\) para \\(k = 1; 2; \\dots ; S - 1\\) y sus condiciones de contorno.\nNota: la deducción es estándar, pero hay que manejar con cuidado las probabilidades de transición condicionales. Surge la duda de si \\(\\hat{h}(0)\\) debe aparecer en el sistema—este punto puede resolverse y debe explicitarse.\n\nResuelva la cuestión del punto 9 en el caso \\(p = 1/2\\) y calcule \\(\\hat{h}(k)\\) para \\(k = 1; 2; \\dots ; S\\). ¿Qué puede decirse de \\(\\hat{h}(0)\\)? La respuesta puede obtenerse usando un argumento de primer paso.",
    "crumbs": [
      "Practicos",
      "Practico 1"
    ]
  },
  {
    "objectID": "practicos_letra/practico1-letra.html#ejercicio-5",
    "href": "practicos_letra/practico1-letra.html#ejercicio-5",
    "title": "Practico 1",
    "section": "Ejercicio 5",
    "text": "Ejercicio 5\nSea \\(n \\in \\mathbb{N}\\) y considere \\(n+1\\) personas numeradas \\(0; 1; \\dots ; n\\) sentadas en círculo. En el instante \\(t = 0\\) la persona \\(0\\) sostiene el brócoli. En tiempos discretos \\(t = 1; 2; \\dots :\\), quien sostiene el brócoli lo pasa a su vecino de la izquierda o de la derecha con probabilidad \\(1/2\\) cada una, de forma independiente de los pasos anteriores. Para \\(t \\ge 0\\), denote por\n\\[ A_t = \\{ \\text{personas que han tocado el brócoli alguna vez hasta el tiempo } t \\} \\]\nel conjunto de personas “tocadas”. El juego termina en el tiempo\n\\[ T := \\inf\\{t \\ge 0 : |A_t| = n\\}; \\]\nes decir, cuando exactamente una persona no ha sido tocada; dicha persona es declarada ganadora y puede comer el brócoli.\nSuponga que usted puede elegir su posición inicial \\(k \\in \\{0; 1; \\dots ; n\\}\\) antes de comenzar. ¿Qué posición elegiría?",
    "crumbs": [
      "Practicos",
      "Practico 1"
    ]
  },
  {
    "objectID": "clases/semana1.html",
    "href": "clases/semana1.html",
    "title": "Semana 1",
    "section": "",
    "text": "Asumimos de base un espacio de probabilidad \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\), donde:\n\n\\(\\Omega\\): espacio muestral\n\\(\\mathcal{F}\\): \\(\\sigma\\)-álgebra de eventos\n\n\\(\\Omega \\in \\mathcal{F}\\)\nsi \\(A \\in \\mathcal{F} \\Rightarrow A^c \\in \\mathcal{F}\\)\nsi \\(\\{A_n\\}_{n \\ge 1}\\) en \\(\\mathcal{F} \\Rightarrow \\bigcup_{n \\ge 1} A_n \\in \\mathcal{F}\\)\n\n\\(\\mathbb{P}: \\mathcal{F} \\rightarrow [0,1]\\) función de probabilidad, tal que:\n\n\\(\\mathbb{P}(\\Omega)=1\\)\n\\(\\sigma\\)-aditividad: \\(\\{A_n\\} \\in \\mathcal{F}\\) incompatibles \\(2 \\ a \\ 2\\)\n\n\n\\(\\qquad \\Rightarrow \\mathbb{P}(\\bigcup_{n \\ge 1} A_n) = \\sum_{n \\ge 1} \\mathbb{P}(A_n)\\)",
    "crumbs": [
      "Clases",
      "Semana 1"
    ]
  },
  {
    "objectID": "clases/semana1.html#tiempo",
    "href": "clases/semana1.html#tiempo",
    "title": "Semana 1",
    "section": "Tiempo:",
    "text": "Tiempo:\n\nDiscreto: \\(T=\\{0, 1, 2, ...\\}=\\mathbb{N}_0=\\{0, 1, 2, ...\\}\\)\n\npor ej: CMTO\n\nContinuo: \\(T = [0, +\\infty)\\)\n\npor ej: Proceso de Poisson",
    "crumbs": [
      "Clases",
      "Semana 1"
    ]
  },
  {
    "objectID": "clases/semana1.html#estados",
    "href": "clases/semana1.html#estados",
    "title": "Semana 1",
    "section": "Estados:",
    "text": "Estados:\n\nDiscretos\nContinuos",
    "crumbs": [
      "Clases",
      "Semana 1"
    ]
  },
  {
    "objectID": "clases/semana1.html#simulación",
    "href": "clases/semana1.html#simulación",
    "title": "Semana 1",
    "section": "Simulación",
    "text": "Simulación\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidyr)\nsimular_regla_greedy &lt;- function(alpha, beta, epsilon, T) {\n  \n  # incializacion de las variables\n  victorias_A &lt;- 0\n  tiradas_A &lt;- 0\n  victorias_B &lt;- 0\n  tiradas_B &lt;- 0\n  \n  # aca se guardan los resultads\n  resultados &lt;- data.frame(\n    tiempo = 1:T,\n    total_recompensa_greedy = numeric(T),\n    recompensa_media_A = numeric(T),\n    recompensa_media_B = numeric(T),\n    eleccion = character(T),\n    moneda_elegida = character(T),\n    recompensa = numeric(T)\n  )\n  \n  for (t in 1:T) {\n    decision &lt;- runif(1)\n    \n    if (decision &lt; epsilon) {\n      moneda_elegida &lt;- sample(c(\"A\", \"B\"), 1)\n      resultados$eleccion[t] &lt;- \"Exploracion\"\n    } \n    else {\n      resultados$eleccion[t] &lt;- \"Mantengo Moneda\"\n      \n      if (tiradas_A == 0 && tiradas_B == 0) {\n        moneda_elegida &lt;- sample(c(\"A\", \"B\"), 1)\n      } \n      ### me aseguro de arracnar con una tirada cada moneda \n      else if (tiradas_A == 0) {\n        moneda_elegida &lt;- \"A\"\n      } else if (tiradas_B == 0) {\n        moneda_elegida &lt;- \"B\"\n      } \n      else if ((victorias_A / tiradas_A) &gt; (victorias_B / tiradas_B)) {\n        moneda_elegida &lt;- \"A\"\n      } else {\n        moneda_elegida &lt;- \"B\"\n      }\n    }\n    \n    if (moneda_elegida == \"A\") {\n      tiradas_A &lt;- tiradas_A + 1\n      recompensa_greedy &lt;- sample(c(1, 0), 1, prob = c(alpha, 1 - alpha))\n      victorias_A &lt;- victorias_A + recompensa_greedy\n      resultados$moneda_elegida[t] &lt;- \"A\"\n      resultados$recompensa[t] &lt;- recompensa_greedy\n    } else {\n      tiradas_B &lt;- tiradas_B + 1\n      recompensa_greedy &lt;- sample(c(1, 0), 1, prob = c(beta, 1 - beta))\n      victorias_B &lt;- victorias_B + recompensa_greedy\n      resultados$moneda_elegida[t] &lt;- \"B\"\n      resultados$recompensa[t] &lt;- recompensa_greedy\n    }\n    \n    resultados$total_recompensa_greedy[t] &lt;- ifelse(t == 1, recompensa_greedy, resultados$total_recompensa_greedy[t-1] + recompensa_greedy)\n    resultados$recompensa_media_A[t] &lt;- ifelse(tiradas_A == 0, NA, victorias_A / tiradas_A)\n    resultados$recompensa_media_B[t] &lt;- ifelse(tiradas_B == 0, NA, victorias_B / tiradas_B)\n  }\n  \n  return(resultados)\n}",
    "crumbs": [
      "Clases",
      "Semana 1"
    ]
  },
  {
    "objectID": "clases/semana1.html#juego-ligeramente-desbalanceado",
    "href": "clases/semana1.html#juego-ligeramente-desbalanceado",
    "title": "Semana 1",
    "section": "Juego ligeramente desbalanceado",
    "text": "Juego ligeramente desbalanceado\n\n\nCode\nset.seed(123)\nalpha_param &lt;- 0.51\nbeta_param &lt;- 0.49\nepsilon_param &lt;- 0.1\nT_param &lt;- 2000\n\nresultados &lt;- simular_regla_greedy(\n  alpha = alpha_param,\n  beta = beta_param,\n  epsilon = epsilon_param,\n  T = T_param\n)\n\n\n\n\nCode\nresultados_largo &lt;- gather(resultados, key = \"moneda\", value = \"recompensa_media\", recompensa_media_A, recompensa_media_B)\n\nresultados_largo %&gt;% \n  ggplot(aes(x = tiempo, y = recompensa_media, color = moneda)) +\n  geom_line(size = 1.2) +\n  geom_hline(aes(yintercept = alpha_param, color = \"Verdadera A\"), linetype = \"dashed\", size = 1) +\n  geom_hline(aes(yintercept = beta_param, color = \"Verdadera B\"), linetype = \"dashed\", size = 1) +\n  labs(title = \"Estimación de Recompensa Media por Moneda\",\n       x = \"Paso de Tiempo\",\n       y = \"Recompensa Media Estimada\",\n       color = \"Moneda\") +\n  scale_color_manual(\n    values = c(\"recompensa_media_A\" = \"blue\", \"recompensa_media_B\" = \"red\", \"Verdadera A\" = \"darkblue\", \"Verdadera B\" = \"darkred\"),\n    labels = c(\"recompensa_media_A\" = expression(hat(alpha)), \"recompensa_media_B\" = expression(hat(beta)), \"Verdadera A\" = \"Verdadera A\", \"Verdadera B\" = \"Verdadera B\")\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nresultados_conteo &lt;- resultados %&gt;%\n  mutate(\n    conteo_A = cumsum(moneda_elegida == \"A\"),\n    conteo_B = cumsum(moneda_elegida == \"B\")\n  ) %&gt;%\n  select(tiempo, conteo_A, conteo_B) %&gt;%\n  gather(key = \"moneda\", value = \"conteo\", -tiempo)\n\nresultados_conteo  %&gt;% \nggplot(aes(x = tiempo, y = conteo, color = moneda)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Evolución de las Tiradas por Moneda\",\n       subtitle = \"La línea más empinada indica la moneda preferida\",\n       x = \"Paso de Tiempo\",\n       y = \"Número de Tiradas\",\n       color = \"Moneda\") +\n  scale_color_manual(values = c(\"conteo_A\" = \"blue\", \"conteo_B\" = \"red\"), labels = c(\"Moneda A\", \"Moneda B\")) +\n  scale_y_continuous(breaks = seq(0, max(resultados_conteo$conteo), by = 100)) +\n\n  theme_minimal()",
    "crumbs": [
      "Clases",
      "Semana 1"
    ]
  },
  {
    "objectID": "clases/semana1.html#juego-ligeramente-desbalanceado-pero-con-ε-greedy-con-decay",
    "href": "clases/semana1.html#juego-ligeramente-desbalanceado-pero-con-ε-greedy-con-decay",
    "title": "Semana 1",
    "section": "Juego ligeramente desbalanceado pero con ε-greedy con decay",
    "text": "Juego ligeramente desbalanceado pero con ε-greedy con decay\n\n\nCode\nset.seed(123)\n\nalpha_param &lt;- 0.51\nbeta_param &lt;- 0.49\nT_param &lt;- 1000\n\nvictorias_A &lt;- 0\ntiradas_A &lt;- 0\nvictorias_B &lt;- 0\ntiradas_B &lt;- 0\n\nresultados &lt;- data.frame(\n  tiempo = 1:T_param,\n  total_recompensa_greedy = numeric(T_param),\n  recompensa_media_A = numeric(T_param),\n  recompensa_media_B = numeric(T_param),\n  eleccion = character(T_param),\n  moneda_elegida = character(T_param),\n  recompensa = numeric(T_param),\n  epsilon_usado = numeric(T_param)\n)\n\nfor (t in 1:T_param) {\n \n  if (t &lt; 100) {\n    epsilon &lt;- 0.9\n  } else if (t == 100) {\n    epsilon &lt;- 0.9\n  } else {\n    \n    decay_rate &lt;- -log(0.001) / (T_param - 100) \n    epsilon &lt;- 0.9 * exp(-decay_rate * (t - 100))\n  }\n\n\n  resultados$epsilon_usado[t] &lt;- epsilon\n  \n  \n  decision &lt;- runif(1)\n  \n  if (decision &lt; epsilon) {\n    moneda_elegida &lt;- sample(c(\"A\", \"B\"), 1)\n    resultados$eleccion[t] &lt;- \"Exploracion\"\n  } \n  else {\n    resultados$eleccion[t] &lt;- \"Mantengo Moneda\"\n    \n    if (tiradas_A == 0 && tiradas_B == 0) {\n      moneda_elegida &lt;- sample(c(\"A\", \"B\"), 1)\n    } \n    else if (tiradas_A == 0) {\n      moneda_elegida &lt;- \"A\"\n    } else if (tiradas_B == 0) {\n      moneda_elegida &lt;- \"B\"\n    } \n    else if ((victorias_A / tiradas_A) &gt; (victorias_B / tiradas_B)) {\n      moneda_elegida &lt;- \"A\"\n    } else {\n      moneda_elegida &lt;- \"B\"\n    }\n  }\n  \n\n  if (moneda_elegida == \"A\") {\n    tiradas_A &lt;- tiradas_A + 1\n    recompensa_greedy &lt;- sample(c(1, 0), 1, prob = c(alpha_param, 1 - alpha_param))\n    victorias_A &lt;- victorias_A + recompensa_greedy\n    resultados$moneda_elegida[t] &lt;- \"A\"\n    resultados$recompensa[t] &lt;- recompensa_greedy\n  } else {\n    tiradas_B &lt;- tiradas_B + 1\n    recompensa_greedy &lt;- sample(c(1, 0), 1, prob = c(beta_param, 1 - beta_param))\n    victorias_B &lt;- victorias_B + recompensa_greedy\n    resultados$moneda_elegida[t] &lt;- \"B\"\n    resultados$recompensa[t] &lt;- recompensa_greedy\n  }\n  \n  resultados$total_recompensa_greedy[t] &lt;- ifelse(t == 1, recompensa_greedy, resultados$total_recompensa_greedy[t-1] + recompensa_greedy)\n  resultados$recompensa_media_A[t] &lt;- ifelse(tiradas_A == 0, NA, victorias_A / tiradas_A)\n  resultados$recompensa_media_B[t] &lt;- ifelse(tiradas_B == 0, NA, victorias_B / tiradas_B)\n}\n\n\n\n\nCode\nresultados  %&gt;% \nggplot(aes(x = tiempo, y = epsilon_usado)) +\n  geom_line(color = \"blue\", size = 1.2) +\n  labs(title = \"Evolución del valor de Epsilon (ε)\",\n       x = \"Paso de Tiempo\",\n       y = \"Valor de Epsilon (ε)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nCode\nresultados_largo &lt;- gather(resultados, key = \"moneda\", value = \"recompensa_media\", recompensa_media_A, recompensa_media_B)\n\nresultados_largo %&gt;% \n  ggplot(aes(x = tiempo, y = recompensa_media, color = moneda)) +\n  geom_line(size = 1.2) +\n  geom_hline(aes(yintercept = alpha_param, color = \"Verdadera A\"), linetype = \"dashed\", size = 1) +\n  geom_hline(aes(yintercept = beta_param, color = \"Verdadera B\"), linetype = \"dashed\", size = 1) +\n  labs(title = \"Estimación de Recompensa Media por Moneda\",\n       x = \"Paso de Tiempo\",\n       y = \"Recompensa Media Estimada\",\n       color = \"Moneda\") +\n  scale_color_manual(\n    values = c(\"recompensa_media_A\" = \"blue\", \"recompensa_media_B\" = \"red\", \"Verdadera A\" = \"darkblue\", \"Verdadera B\" = \"darkred\"),\n    labels = c(\"recompensa_media_A\" = expression(hat(alpha)), \"recompensa_media_B\" = expression(hat(beta)), \"Verdadera A\" = \"Verdadera A\", \"Verdadera B\" = \"Verdadera B\")\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nresultados_conteo &lt;- resultados %&gt;%\n  mutate(\n    conteo_A = cumsum(moneda_elegida == \"A\"),\n    conteo_B = cumsum(moneda_elegida == \"B\")\n  ) %&gt;%\n  select(tiempo, conteo_A, conteo_B) %&gt;%\n  gather(key = \"moneda\", value = \"conteo\", -tiempo)\n\nresultados_conteo  %&gt;% \nggplot(aes(x = tiempo, y = conteo, color = moneda)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Evolución de las Tiradas por Moneda\",\n       subtitle = \"La línea más empinada indica la moneda preferida\",\n       x = \"Paso de Tiempo\",\n       y = \"Número de Tiradas\",\n       color = \"Moneda\") +\n  scale_color_manual(values = c(\"conteo_A\" = \"blue\", \"conteo_B\" = \"red\"), labels = c(\"Moneda A\", \"Moneda B\")) +\n  scale_y_continuous(breaks = seq(0, max(resultados_conteo$conteo), by = 100)) +\n\n  theme_minimal()",
    "crumbs": [
      "Clases",
      "Semana 1"
    ]
  },
  {
    "objectID": "clases/semana1.html#primer-caso",
    "href": "clases/semana1.html#primer-caso",
    "title": "Semana 1",
    "section": "Primer caso",
    "text": "Primer caso\n\n\nCode\nalpha_param &lt;- 0.7  # proabilidad de ganar la moneda a\nbeta_param &lt;- 0.5   # proabilidad de ganar la moneda b\nepsilon_param &lt;- 0.1 # proabilidad de explorar\nT_param &lt;- 1000     # iteraciones\n\nresultados &lt;- simular_regla_greedy(\n  alpha = alpha_param,\n  beta = beta_param,\n  epsilon = epsilon_param,\n  T = T_param\n)\n\n\n\n\nCode\nresultados_largo &lt;- gather(resultados, key = \"moneda\", value = \"recompensa_media\", recompensa_media_A, recompensa_media_B)\n\nresultados_largo %&gt;% \n  ggplot(aes(x = tiempo, y = recompensa_media, color = moneda)) +\n  geom_line(size = 1.2) +\n  geom_hline(aes(yintercept = alpha_param, color = \"Verdadera A\"), linetype = \"dashed\", size = 1) +\n  geom_hline(aes(yintercept = beta_param, color = \"Verdadera B\"), linetype = \"dashed\", size = 1) +\n  labs(title = \"Estimación de Recompensa Media por Moneda\",\n       x = \"Paso de Tiempo\",\n       y = \"Recompensa Media Estimada\",\n       color = \"Moneda\") +\n  scale_color_manual(\n    values = c(\"recompensa_media_A\" = \"blue\", \"recompensa_media_B\" = \"red\", \"Verdadera A\" = \"darkblue\", \"Verdadera B\" = \"darkred\"),\n    labels = c(\"recompensa_media_A\" = expression(hat(alpha)), \"recompensa_media_B\" = expression(hat(beta)), \"Verdadera A\" = \"Verdadera A\", \"Verdadera B\" = \"Verdadera B\")\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nresultados_conteo &lt;- resultados %&gt;%\n  mutate(\n    conteo_A = cumsum(moneda_elegida == \"A\"),\n    conteo_B = cumsum(moneda_elegida == \"B\")\n  ) %&gt;%\n  select(tiempo, conteo_A, conteo_B) %&gt;%\n  gather(key = \"moneda\", value = \"conteo\", -tiempo)\n\nresultados_conteo  %&gt;% \nggplot(aes(x = tiempo, y = conteo, color = moneda)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Evolución de las Tiradas por Moneda\",\n       subtitle = \"La línea más empinada indica la moneda preferida\",\n       x = \"Paso de Tiempo\",\n       y = \"Número de Tiradas\",\n       color = \"Moneda\") +\n  scale_color_manual(values = c(\"conteo_A\" = \"blue\", \"conteo_B\" = \"red\"), labels = c(\"Moneda A\", \"Moneda B\")) +\n  scale_y_continuous(breaks = seq(0, max(resultados_conteo$conteo), by = 100)) +\n\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nresultados  %&gt;% \nggplot(aes(x = tiempo, y = moneda_elegida, color = factor(recompensa))) +\n  geom_point(alpha = 0.7, size = 3) +\n  labs(title = \"Resultados de cada Tirada\",\n       x = \"Paso de Tiempo\",\n       y = \"Moneda Elegida\",\n       color = \"Resultado\") +\n  scale_color_manual(values = c(\"1\" = \"green\", \"0\" = \"red\"), labels = c(\"1\" = \"Cara\", \"0\" = \"Cruz\")) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Clases",
      "Semana 1"
    ]
  }
]